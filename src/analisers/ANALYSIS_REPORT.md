# Анализ производительности решателя Unit Commitment

## Обзор

Проведен анализ 56 успешно решенных примеров из датасетов CA, FERC и RTS-GMLC для выявления зависимости времени решения
от параметров задачи.

## Ключевые выводы

### 1. Основные факторы, влияющие на время решения

**Положительная корреляция** (увеличивают время решения):

1. **avg_demand** (0.797) - Средний спрос является сильнейшим предиктором
2. **peak_demand** (0.791) - Пиковый спрос тесно связан со временем решения
3. **total_pwl_points** (0.747) - Количество точек кусочно-линейной аппроксимации
4. **problem_size** (0.744) - Общий размер задачи (переменные × ограничения)
5. **total_reserves** (0.722) - Общие резервы мощности
6. **approx_continuous_vars** (0.712) - Количество непрерывных переменных
7. **approx_total_vars** (0.664) - Общее количество переменных
8. **n_thermal_gens** (0.658) - Количество тепловых генераторов
9. **reserve_ratio** (0.595) - Отношение резервов к пиковому спросу

**Отрицательная корреляция** (уменьшают время решения):

1. **startup_per_gen** (-0.728) - Количество категорий запуска на генератор
    - Это неожиданный результат, указывающий что датасеты с большим числом категорий запуска на генератор имеют меньшие
      размеры задач
2. **n_renewable_gens** (-0.362) - Количество возобновляемых генераторов
3. **must_run_ratio** (-0.348) - Доля генераторов с обязательным запуском
4. **binary_ratio** (-0.236) - Доля бинарных переменных

### 2. Характеристики датасетов

| Dataset  | Примеры | Min time (s) | Max time (s) | Avg time (s) | Avg vars | Avg gens |
|----------|---------|--------------|--------------|--------------|----------|----------|
| CA       | 20      | 124.42       | 283.82       | ~210         | 305,664  | 610      |
| FERC     | 24      | 3066.26      | 18,982.70    | ~7,100       | 477,696  | 956      |
| RTS-GMLC | 12      | 16.74        | 196.20       | ~87          | 44,544   | 73       |

**Выводы по датасетам:**

- **RTS-GMLC**: Самые быстрые (73 генератора, 44K переменных)
- **CA**: Средние по сложности (610 генераторов, 306K переменных)
- **FERC**: Самые сложные (956 генераторов, 478K переменных, время до 5+ часов)

### 3. Самые медленные примеры

Топ-3 самых долгих решений (все из FERC):

1. **2015-01-01_hw.json**: 18,983 сек (~5.3 часа) - 934 генератора, 472K переменных
2. **2015-08-01_hw.json**: 18,229 сек (~5.1 часа) - 978 генераторов, 485K переменных
3. **2015-10-01_lw.json**: 8,474 сек (~2.4 часа) - 934 генератора, 472K переменных

### 4. Самые быстрые примеры

Топ-3 самых быстрых решений (все из RTS-GMLC):

1. **2020-07-06.json**: 16.74 сек - 73 генератора, 45K переменных
2. **2020-06-09.json**: 18.08 сек - 73 генератора, 45K переменных
3. **2020-08-12.json**: 19.09 сек - 73 генератора, 45K переменных

### 5. Регрессионный анализ

**Linear Regression**: R^2 = -7.609 (плохое качество модели)

- Линейная модель не подходит из-за нелинейных зависимостей

**Random Forest**: R^2 = -5.495 (плохое качество модели)

- Важнейшие признаки по Random Forest:
    1. total_reserves (33.0%)
    2. peak_demand (21.0%)
    3. total_pwl_points (11.3%)

Отрицательные R^2 указывают на сильную нелинейность и возможно недостаточность данных для обучения модели.

## Практические рекомендации

### Факторы, критичные для времени решения:

1. **Размер задачи** - Основной фактор
    - Количество генераторов напрямую влияет на сложность
    - Примеры с >900 генераторами требуют часов решения
    - Примеры с <100 генераторами решаются за минуты

2. **Спрос и резервы** - Второстепенные факторы
    - Высокий пиковый спрос усложняет задачу
    - Большие резервы увеличивают пространство решений

3. **Сложность генераторов** - Влияет умеренно
    - Больше точек PWL = более точная модель, но дольше решение
    - Больше категорий запуска = сложнее логика, но в данных это коррелирует с меньшими задачами

### Для ускорения решения:

1. **Уменьшить горизонт планирования** (если возможно)
2. **Упростить PWL аппроксимацию** (меньше точек на генератор)
3. **Уменьшить количество генераторов** через агрегацию
4. **Использовать warm start** для похожих задач
5. **Настроить MIP gap** для компромисса точность/время

## Визуализации

Созданы следующие графики в папке `analysis_plots/`:

1. **correlation_heatmap.png** - Матрица корреляций параметров
2. **solve_time_vs_parameters.png** - Время решения vs ключевые параметры
3. **problem_size_analysis.png** - Анализ размера задачи (log-log графики)
4. **reserve_impact.png** - Влияние резервов на время решения
5. **dataset_comparison.png** - Сравнение датасетов
6. **generator_complexity.png** - Анализ сложности генераторов

## Использование скрипта

```bash
# Основной анализ
python analyze_solver_performance.py

# С другим файлом результатов
python analyze_solver_performance.py --input test_results.csv

# Без графиков (только статистика)
python analyze_solver_performance.py --no-plots

# Без регрессии
python analyze_solver_performance.py --no-regression

# Помощь
python analyze_solver_performance.py --help
```

## Дополнительные исследования

Для более глубокого понимания рекомендуется:

1. Сгенерировать синтетические примеры с контролируемыми параметрами
2. Протестировать влияние каждого параметра изолированно
3. Исследовать влияние структуры сети (не отражено в текущих параметрах)
4. Попробовать другие решатели (Gurobi, CPLEX) для сравнения
5. Изучить влияние gap tolerance на время решения

## Заключение

Время решения задачи Unit Commitment в первую очередь определяется:

- **Размером задачи** (количество генераторов и переменных)
- **Спросом** (пиковый и средний)
- **Сложностью моделирования** (PWL точки, резервы)

Датасеты сильно различаются по сложности: RTS-GMLC решается за секунды, CA за минуты, а FERC может требовать часов
работы решателя.
